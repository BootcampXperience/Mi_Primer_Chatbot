{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "9A2oSLDivrbN",
        "kDRIGcy62JuE",
        "qQEIdACV2IE4",
        "IVJ6UmQV3n4T",
        "LMEwexpz4gdI"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# 1. Configurar ambiente"
      ],
      "metadata": {
        "id": "9A2oSLDivrbN"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "UD0OObFGtZVJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c5e5f9ba-ef66-4d97-c5a8-65fdd435cf68"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting jellyfish\n",
            "  Downloading jellyfish-0.11.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m14.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: jellyfish\n",
            "Successfully installed jellyfish-0.11.2\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting transformers\n",
            "  Downloading transformers-4.29.2-py3-none-any.whl (7.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.1/7.1 MB\u001b[0m \u001b[31m46.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.12.0)\n",
            "Collecting huggingface-hub<1.0,>=0.14.1 (from transformers)\n",
            "  Downloading huggingface_hub-0.14.1-py3-none-any.whl (224 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m224.5/224.5 kB\u001b[0m \u001b[31m19.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.22.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (23.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2022.10.31)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.27.1)\n",
            "Collecting tokenizers!=0.11.3,<0.14,>=0.11.1 (from transformers)\n",
            "  Downloading tokenizers-0.13.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m48.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.65.0)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.14.1->transformers) (2023.4.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.14.1->transformers) (4.5.0)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2022.12.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4)\n",
            "Installing collected packages: tokenizers, huggingface-hub, transformers\n",
            "Successfully installed huggingface-hub-0.14.1 tokenizers-0.13.3 transformers-4.29.2\n",
            "2023-05-27 20:59:53.254236: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting es-core-news-md==3.5.0\n",
            "  Downloading https://github.com/explosion/spacy-models/releases/download/es_core_news_md-3.5.0/es_core_news_md-3.5.0-py3-none-any.whl (42.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.3/42.3 MB\u001b[0m \u001b[31m16.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: spacy<3.6.0,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from es-core-news-md==3.5.0) (3.5.2)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->es-core-news-md==3.5.0) (3.0.12)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->es-core-news-md==3.5.0) (1.0.4)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->es-core-news-md==3.5.0) (1.0.9)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->es-core-news-md==3.5.0) (2.0.7)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->es-core-news-md==3.5.0) (3.0.8)\n",
            "Requirement already satisfied: thinc<8.2.0,>=8.1.8 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->es-core-news-md==3.5.0) (8.1.9)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->es-core-news-md==3.5.0) (1.1.1)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->es-core-news-md==3.5.0) (2.4.6)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->es-core-news-md==3.5.0) (2.0.8)\n",
            "Requirement already satisfied: typer<0.8.0,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->es-core-news-md==3.5.0) (0.7.0)\n",
            "Requirement already satisfied: pathy>=0.10.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->es-core-news-md==3.5.0) (0.10.1)\n",
            "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->es-core-news-md==3.5.0) (6.3.0)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->es-core-news-md==3.5.0) (4.65.0)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->es-core-news-md==3.5.0) (1.22.4)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->es-core-news-md==3.5.0) (2.27.1)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->es-core-news-md==3.5.0) (1.10.7)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->es-core-news-md==3.5.0) (3.1.2)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->es-core-news-md==3.5.0) (67.7.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->es-core-news-md==3.5.0) (23.1)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->es-core-news-md==3.5.0) (3.3.0)\n",
            "Requirement already satisfied: typing-extensions>=4.2.0 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4->spacy<3.6.0,>=3.5.0->es-core-news-md==3.5.0) (4.5.0)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.6.0,>=3.5.0->es-core-news-md==3.5.0) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.6.0,>=3.5.0->es-core-news-md==3.5.0) (2022.12.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.6.0,>=3.5.0->es-core-news-md==3.5.0) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.6.0,>=3.5.0->es-core-news-md==3.5.0) (3.4)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.10/dist-packages (from thinc<8.2.0,>=8.1.8->spacy<3.6.0,>=3.5.0->es-core-news-md==3.5.0) (0.7.9)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.10/dist-packages (from thinc<8.2.0,>=8.1.8->spacy<3.6.0,>=3.5.0->es-core-news-md==3.5.0) (0.0.4)\n",
            "Requirement already satisfied: click<9.0.0,>=7.1.1 in /usr/local/lib/python3.10/dist-packages (from typer<0.8.0,>=0.3.0->spacy<3.6.0,>=3.5.0->es-core-news-md==3.5.0) (8.1.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->spacy<3.6.0,>=3.5.0->es-core-news-md==3.5.0) (2.1.2)\n",
            "Installing collected packages: es-core-news-md\n",
            "Successfully installed es-core-news-md-3.5.0\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the package via spacy.load('es_core_news_md')\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import re\n",
        "import os\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "!pip install jellyfish\n",
        "import jellyfish\n",
        "!pip install transformers\n",
        "from transformers import BertForSequenceClassification\n",
        "from transformers import BertTokenizer\n",
        "import spacy\n",
        "!python -m spacy download es_core_news_md\n",
        "nlp = spacy.load('es_core_news_md')\n",
        "from bs4 import BeautifulSoup\n",
        "import requests\n",
        "import torch\n",
        "import random"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#2. Tratamiento de datos"
      ],
      "metadata": {
        "id": "kDRIGcy62JuE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Función para encontrar la raiz de las palabras\n",
        "def raiz(palabra):\n",
        "  radio=0\n",
        "  palabra_encontrada=palabra\n",
        "  for word in lista_verbos:\n",
        "    confianza = jellyfish.jaro_winkler(palabra, word)\n",
        "    if (confianza>=0.92 and confianza>=radio):\n",
        "      radio=confianza\n",
        "      palabra_encontrada=word\n",
        "  return palabra_encontrada\n",
        "\n",
        "def tratamiento_texto(texto):\n",
        "  trans = str.maketrans('áéíóú','aeiou')\n",
        "  texto = texto.lower()\n",
        "  texto = texto.translate(trans)\n",
        "  texto = re.sub(r\"[^\\w\\s]\", '', texto)\n",
        "  texto = \" \".join(texto.split())\n",
        "  return texto\n",
        "\n",
        "#Función para normalizar la palabra\n",
        "def normalizar(texto):\n",
        "  doc = nlp(texto)\n",
        "  tokens=[]\n",
        "  if len(doc)<=3:\n",
        "    for t in doc:\n",
        "      if t.pos_=='VERB':\n",
        "        tokens.append(raiz(t.lemma_))\n",
        "      else:\n",
        "        tokens.append(t.lemma_)\n",
        "  else:\n",
        "    for t in doc:\n",
        "      if (t.pos_ in ('VERB','PROPN','PRON','NOUN','AUX','SCONJ','DET','ADJ','ADV') or any(t.dep_.startswith(elemento) for elemento in ['ROOT'])):\n",
        "        if t.pos_=='VERB':\n",
        "          tokens.append(raiz(t.lemma_))\n",
        "        else:\n",
        "          tokens.append(t.lemma_)\n",
        "  tokens = list(dict.fromkeys(tokens))\n",
        "  tokens = tokens[:10]\n",
        "  tokens = ' '.join(tokens)\n",
        "  return tratamiento_texto(tokens)"
      ],
      "metadata": {
        "id": "N-__6F0I2MjG"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3. Cargar bases de conocimiento"
      ],
      "metadata": {
        "id": "qQEIdACV2IE4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Importando verbos en español\n",
        "headers = {'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/111.0.0.0 Safari/537.36'}\n",
        "trans = str.maketrans('áéíóú','aeiou')\n",
        "lista_verbos=[]\n",
        "url = ['https://www.ejemplos.co/verbos-mas-usados-en-espanol/',\n",
        "       'https://www.ejemplos.co/tipos-de-verbos/',\n",
        "       'https://www.ejemplos.co/verbos-predicativos/',\n",
        "       'https://www.ejemplos.co/verbos-personales/',\n",
        "       'https://www.ejemplos.co/verbos-irregulares/',\n",
        "       'https://www.ejemplos.co/verbos/',\n",
        "       'https://www.ejemplos.co/100-ejemplos-de-verbos-regulares/',\n",
        "       'https://www.ejemplos.co/verbos-del-decir/',\n",
        "       'https://www.ejemplos.co/verbos-con-a/',\n",
        "       'https://www.ejemplos.co/verbos-con-b/',\n",
        "       'https://www.ejemplos.co/verbos-con-c/',\n",
        "       'https://www.ejemplos.co/verbos-con-d/',\n",
        "       'https://www.ejemplos.co/verbos-con-e/',\n",
        "       'https://www.ejemplos.co/verbos-con-f/',\n",
        "       'https://www.ejemplos.co/verbos-con-g/',\n",
        "       'https://www.ejemplos.co/verbos-con-h/',\n",
        "       'https://www.ejemplos.co/verbos-con-i/',\n",
        "       'https://www.ejemplos.co/verbos-con-j/',\n",
        "       'https://www.ejemplos.co/verbos-con-k/',\n",
        "       'https://www.ejemplos.co/verbos-con-l/',\n",
        "       'https://www.ejemplos.co/verbos-con-ll/',\n",
        "       'https://www.ejemplos.co/verbos-con-m/',\n",
        "       'https://www.ejemplos.co/verbos-con-n/',\n",
        "       'https://www.ejemplos.co/verbos-con-o/',\n",
        "       'https://www.ejemplos.co/verbos-con-p/',\n",
        "       'https://www.ejemplos.co/verbos-con-q/',\n",
        "       'https://www.ejemplos.co/verbos-con-r/',\n",
        "       'https://www.ejemplos.co/verbos-con-s/',\n",
        "       'https://www.ejemplos.co/verbos-con-t/',\n",
        "       'https://www.ejemplos.co/verbos-con-u/',\n",
        "       'https://www.ejemplos.co/verbos-con-v/',\n",
        "       'https://www.ejemplos.co/verbos-con-w/',\n",
        "       'https://www.ejemplos.co/verbos-con-x/',\n",
        "       'https://www.ejemplos.co/verbos-con-y/',\n",
        "       'https://www.ejemplos.co/verbos-con-z/']\n",
        "\n",
        "for i in range(len(url)):\n",
        "  try:\n",
        "    respuesta = requests.get(url[i], headers=headers)\n",
        "    respuesta = respuesta.content.decode('utf-8')\n",
        "    bases = pd.read_html(respuesta)\n",
        "    for i, df in enumerate(bases):\n",
        "      for idx,row in bases[i].iterrows():     \n",
        "          _ = [lista_verbos.append(re.sub(r\"\\((.*?)\\)\", '', x.lower()).strip().translate(trans)) for x in row[0].split('/')]\n",
        "          _ = [lista_verbos.append(re.sub(r\"\\((.*?)\\)\", '', x.lower()).strip().translate(trans)) for x in row[1].split('/')]\n",
        "          _ = [lista_verbos.append(re.sub(r\"\\((.*?)\\)\", '', x.lower()).strip().translate(trans)) for x in row[2].split('/')]\n",
        "  except Exception:\n",
        "    continue\n",
        "lista_verbos = [elemento for elemento in lista_verbos if len(elemento) != 2]\n",
        "lista_verbos=list(set(lista_verbos))\n",
        "\n",
        "#Importando bases de dialogo fluído\n",
        "txt_folder_path = '/content'\n",
        "lista_documentos=[x for x in os.listdir(txt_folder_path) if x.endswith(\".txt\")]\n",
        "lista_dialogos, lista_dialogos_respuesta, lista_tipo_dialogo = [],[],[]\n",
        "for idx in range(len(lista_documentos)):\n",
        "  f=open(txt_folder_path+'/'+lista_documentos[idx], 'r', encoding='utf-8', errors='ignore')\n",
        "  flag,posicion = True,0\n",
        "  for line in f.read().split('\\n'):\n",
        "    if flag:\n",
        "      line = tratamiento_texto(line)\n",
        "      lista_dialogos.append(line)\n",
        "      lista_tipo_dialogo.append(lista_documentos[idx].replace('.txt', ''))\n",
        "    else:\n",
        "      lista_dialogos_respuesta.append(line)\n",
        "      posicion+=1\n",
        "    flag=not flag\n",
        "\n",
        "#Creando Dataframe de diálogos\n",
        "datos = {'dialogo':lista_dialogos,'respuesta':lista_dialogos_respuesta,'tipo':lista_tipo_dialogo,'interseccion':0,'similarity':0,'jaro_winkler':0,'probabilidad':0}\n",
        "df_dialogo = pd.DataFrame(datos)\n",
        "df_dialogo = df_dialogo.drop_duplicates(keep='first')\n",
        "df_dialogo.reset_index(drop=True, inplace=True)"
      ],
      "metadata": {
        "id": "8DDVG_F22IvU"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 4. Buscar respuesta del Chatbot"
      ],
      "metadata": {
        "id": "IVJ6UmQV3n4T"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Función para verificar si el usuário inició un diálogo\n",
        "def dialogo(user_response):\n",
        "  df = df_dialogo.copy()\n",
        "  vectorizer = TfidfVectorizer()\n",
        "  dialogos_numero = vectorizer.fit_transform(df_dialogo['dialogo'])\n",
        "  respuesta_numero = vectorizer.transform([user_response])\n",
        "  for idx,row in df.iterrows():\n",
        "    df.at[idx,'interseccion'] = len(set(user_response.split()) & set(row['dialogo'].split()))/len(user_response.split())\n",
        "    df.at[idx,'similarity'] = cosine_similarity(dialogos_numero[idx], respuesta_numero)[0][0]\n",
        "    df.at[idx,'jaro_winkler'] = jellyfish.jaro_winkler(user_response,row['dialogo'])\n",
        "    df.at[idx,'probabilidad'] = max(df.at[idx,'interseccion'],df.at[idx,'similarity'],df.at[idx,'jaro_winkler'])\n",
        "  df.sort_values(by=['probabilidad','jaro_winkler'], inplace=True, ascending=False)\n",
        "  return df.head(3)\n",
        "\n",
        "#Cargar el modelo entrenado\n",
        "ruta_modelo = '/content/modelo'\n",
        "Modelo_TF = BertForSequenceClassification.from_pretrained(ruta_modelo)\n",
        "tokenizer_TF = BertTokenizer.from_pretrained(ruta_modelo)\n",
        "\n",
        "def clasificacion_modelo(pregunta):\n",
        "  frase = normalizar(pregunta)\n",
        "  tokens = tokenizer_TF.encode_plus(\n",
        "      frase,\n",
        "      add_special_tokens=True,\n",
        "      max_length=128,\n",
        "      padding='max_length',\n",
        "      truncation=True,\n",
        "      return_tensors='pt'\n",
        "  )\n",
        "  input_ids = tokens['input_ids']\n",
        "  attention_mask = tokens['attention_mask']\n",
        "\n",
        "  with torch.no_grad():\n",
        "      outputs = Modelo_TF(input_ids, attention_mask)\n",
        "\n",
        "  etiquetas_predichas = torch.argmax(outputs.logits, dim=1)\n",
        "  etiquetas_decodificadas = etiquetas_predichas.tolist()\n",
        "\n",
        "  diccionario = {3: 'Continuacion', 10: 'Nombre', 2: 'Contacto', 13: 'Saludos', 14: 'Sentimiento', 9: 'Identidad', 15: 'Usuario', 6: 'ElProfeAlejo', 1: 'Aprendizaje', 0: 'Agradecimiento', 5: 'Edad', 4: 'Despedida', 11: 'Origen', 12: 'Otros', 7: 'Error', 8: 'Funcion'}\n",
        "  llave_buscada = etiquetas_decodificadas[0]\n",
        "  clase_encontrada = diccionario[llave_buscada]\n",
        "\n",
        "  #Buscar respuesta más parecida en la clase encontrada\n",
        "  df = df_dialogo[df_dialogo['tipo'] == clase_encontrada]\n",
        "  df.reset_index(inplace=True)\n",
        "  vectorizer = TfidfVectorizer()\n",
        "  dialogos_num = vectorizer.fit_transform(df['dialogo'])\n",
        "  pregunta_num = vectorizer.transform([tratamiento_texto(pregunta)])\n",
        "  similarity_scores = cosine_similarity(dialogos_num, pregunta_num)\n",
        "  indice_pregunta_proxima = similarity_scores.argmax()\n",
        "  return clase_encontrada, df['respuesta'][indice_pregunta_proxima]"
      ],
      "metadata": {
        "id": "Bpxajyck3pav"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 5. Ejecutar Chatbot"
      ],
      "metadata": {
        "id": "LMEwexpz4gdI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pregunta='que es machine learning?'\n",
        "user_response = tratamiento_texto(pregunta)\n",
        "respuesta = dialogo(user_response)\n",
        "respuesta"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 143
        },
        "id": "X_wq8HMP4hmU",
        "outputId": "6001a29d-6f5e-4ad8-a95e-41b66a8f885c"
      },
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "            dialogo                                          respuesta  \\\n",
              "971    que es la ia  La Inteligencia Artificial (IA) es un campo de...   \n",
              "308  que es el amor  El amor es un sentimiento profundo de afecto y...   \n",
              "963      que es api  API es el acrónimo de Application Programming ...   \n",
              "\n",
              "            tipo  interseccion  similarity  jaro_winkler  probabilidad  \n",
              "971        Otros           0.5    0.535875      0.887681      0.887681  \n",
              "308  Sentimiento           0.5    0.523251      0.867989      0.867989  \n",
              "963        Otros           0.5    0.559535      0.858261      0.858261  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-e3bcedf2-2aaa-459a-ada0-48ab9c6169b8\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>dialogo</th>\n",
              "      <th>respuesta</th>\n",
              "      <th>tipo</th>\n",
              "      <th>interseccion</th>\n",
              "      <th>similarity</th>\n",
              "      <th>jaro_winkler</th>\n",
              "      <th>probabilidad</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>971</th>\n",
              "      <td>que es la ia</td>\n",
              "      <td>La Inteligencia Artificial (IA) es un campo de...</td>\n",
              "      <td>Otros</td>\n",
              "      <td>0.5</td>\n",
              "      <td>0.535875</td>\n",
              "      <td>0.887681</td>\n",
              "      <td>0.887681</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>308</th>\n",
              "      <td>que es el amor</td>\n",
              "      <td>El amor es un sentimiento profundo de afecto y...</td>\n",
              "      <td>Sentimiento</td>\n",
              "      <td>0.5</td>\n",
              "      <td>0.523251</td>\n",
              "      <td>0.867989</td>\n",
              "      <td>0.867989</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>963</th>\n",
              "      <td>que es api</td>\n",
              "      <td>API es el acrónimo de Application Programming ...</td>\n",
              "      <td>Otros</td>\n",
              "      <td>0.5</td>\n",
              "      <td>0.559535</td>\n",
              "      <td>0.858261</td>\n",
              "      <td>0.858261</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-e3bcedf2-2aaa-459a-ada0-48ab9c6169b8')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-e3bcedf2-2aaa-459a-ada0-48ab9c6169b8 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-e3bcedf2-2aaa-459a-ada0-48ab9c6169b8');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 70
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "clase = clasificacion_modelo(pregunta)\n",
        "print(clase[0])\n",
        "print(clase[1])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IYV7plmXYl86",
        "outputId": "d15a33b4-76ae-4c86-cceb-17dc6b365481"
      },
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Otros\n",
            "Python es un lenguaje de programación interpretado cuya filosofía hace hincapié en la legibilidad de su código. Fue creado por Guido van Rossum, y liberado al público en 1991. Python tiene una sintaxis clara y concisa, lo que la convierte en un lenguaje ideal para la programación en general. Está diseñado para ser fácilmente legible, lo que lo hace ideal para la prototipación y el desarrollo de proyectos a gran escala.\n"
          ]
        }
      ]
    }
  ]
}